# HW14
## 什么是Life long learning
Life long learning意思是终身学习，是指一直使用同一个神经网络去学习不同的任务。
实现life long learning大致分为三方面：knowledge retention，knowledge transfer，model expansion。
### 为什么不让一个模型就学习一个任务，而是要让一个模型学习多个任务？
如果是让一个模型学习一个任务，那实现一个功能多样的机器人就会面临下面这两个问题：
1. 最终没有足够的空间存储所有模型
2. 不同的任务之间不能够互通有无，没法从别的任务里面学到在单一任务中没法学到的知识
### 终身学习和迁移学习的对比
二者虽然都是让机器去学习多个任务，但是关注点不一样，迁移学习里在意的是机器在task1上学到的技能能不能对task2有帮助，所以只看在task2上机器做的好不好，终身学习关注的是机器学完task2后还能不能解决task1也就是说迁移学习是关注新任务做的怎么样，终身学习是关注旧任务做的怎么样。\
![](../Pictures/2022-08-21-15-13-52.png)
### LLL的几个评估指标：
评估指标有三个：
1. accuracy是最后一行取平均值
2. backward transfer是蓝色箭头指向的相减，R1,1就是刚学完task1时在task1上效果怎么样，RT,1是学完所有任务时在task1上效果怎么样，是衡量遗忘程度，这两个值相减的结果一般会是负的
3. forward transfer是看没有接触这个task之前模型能学到什么程度，RT-1,T减R0,T是只学了前面T-1个任务，没有学task T时，这个时候在taskT上测试，与最初的随机初始化的模型相比，在taskT上有多大的提升
![](../Pictures/2022-08-21-15-20-27.png)
## 几种catastrophic forget的可能解法：
###  Selective Synaptic Plasticity: 
只让网络中某些神经元或者某些神经元之间的连接具有可塑性，其余参数固化，该方法也称为Regularization-based Approach
每一个参数对学习完的任务的重要程度是不一样的，学习新任务时，对旧任务比较重要的参数最好保持不变，只去改对旧任务不重要的参数
![](../Pictures/2022-08-21-15-21-33.png)
### Gradient Episodic Memory(GEM)：
GEM不是在参数上做限制，是在梯度更新的方向上做限制，红色虚线是在新任务上的梯度更新方向，绿色是如果还在旧任务上接着训练的梯度更新方向，然后对红色虚线做一些修正，用红色实线做最后的梯度更新方向。 \
缺陷：需要存旧任务的数据才能算在旧任务上的梯度更新方向，LLL追求的是不保存旧任务的数据。 \
![](../Pictures/2022-08-21-15-22-42.png)
##  Additional Neural Resource Allocation:
改变一下分配在不同任务上的神经网络资源
### Progressive Neural Networks
训练task2的重新建立一个模型，然后用task1的最终参数做task2的初始参数，不去动task1的模型，从而在task1上的效果也不会有大变化，训练task3的时候再开一个模型，用task1和task2的最终参数做task3的初始参数。 \
缺陷：任务多的时候，存所有模型会耗费内存。 \
![](../Pictures/2022-08-21-15-24-17.png)
### PackNet
每一个圆圈代表一个参数位置，一开始创建一个大的网络，每个任务只分配一定量的参数位置，这样旧任务的参数就不会改变。 \
![](../Pictures/2022-08-21-15-25-20.png)
### Compacting,Picking,and Growing(CPG)
CPG就是Progressive Neural Networks和PackNet的结合，每一次既可以新增参数，又会只分配一部分参数给新任务做训练。 \
![](../Pictures/2022-08-21-15-25-26.png)
## Memory Reply
用一个模型去生成数据，假设是模型A
训练task1的时候用task1的数据训练出一个模型B，同时用模型A生成一份属于task1的数据dataset-task1
训练task2的时候用task2的数据加dataset-task1,在B的基础上训练出模型C，同时用模型A生成属于task1和task2的数据dataset-task1&2，依此类推
实验证明Generating Data可以接近LLL的上限，也就是可以接近Multi-task training的结果。 \
![](../Pictures/2022-08-21-15-26-14.png)
## 课后作业
1. EWC（Elastic Weight Consolidation）
   - 大致思想：一般情况下，在训练模型的时候，训练完任务A之后直接去训练任务B，再通过任务B训练出来的参数去测试任务A，对于这样所训练出来的模型产生的结果就是如下图蓝色箭头所示，当使用L2正则化的时候，训练所产生的权重会产生变化偏离正确的信息，所以就会导致了绿色箭头的情况，而EWC则是红色箭头，通过Fisher信息矩阵表示模型近似的协方差，来代表模型信息的分布，
2. MAS（Memory Aware Synapses）
   - 大致思想：在每一个任务训练完之后有一些参数的权重对于当前任务很重要，给予这些参数一些权重来表示参数的重要性。在进行下一个任务的训练时，在上个任务中拥有大的权重的参数进行小浮动的更新，拥有小权重的参数进行较大幅度的更新。
3. SI（Synaptic Intelligence）
   - 大致思想：提出了一种代理损失函数来代表过去任务的损失，下图黑色代表之前任务的损失，绿色是代理损失，用代理损失去接近之前任务的真实损失，这个方法的过程实际上跟EWC相似，与EWC不同的是EWC会依赖Fisher信息矩阵。
4. Rwalk（Remanian Walk for Incremental Learning）
- RWalk是EWC的推广
5. SCP（Sliced Cramer Preservation）
![](../Pictures/2022-08-23-14-46-34.png)
结果图：
![](../Pictures/2022-08-23-14-46-49.png)