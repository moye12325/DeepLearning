{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw12_reinforcement_learning_english_version_ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a680dd0380646beb5d79a2c9c0abd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89faed095217421796547389e01e53ac",
              "IPY_MODEL_8b785f3f08ad4781bcb842215fbcdfac",
              "IPY_MODEL_c8c35d7a8e38450ea308c1a11ae81c77"
            ],
            "layout": "IPY_MODEL_f372b67e0935459ba854c308cc81a4c6"
          }
        },
        "89faed095217421796547389e01e53ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29c75404fa948449a5e797a2acc9eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_7bedb1dbaedf40a29e9e77452397cb2b",
            "value": "Total: -123.7, Final: -100.0:  41%"
          }
        },
        "8b785f3f08ad4781bcb842215fbcdfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034f4c188c504d0d983381273d2073cf",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e7eba784e6143088d258ecd6d4c9f2d",
            "value": 206
          }
        },
        "c8c35d7a8e38450ea308c1a11ae81c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23994c45fc6a48fc8026c2a8e16bfa4a",
            "placeholder": "​",
            "style": "IPY_MODEL_8127a146e9864f0ebe6080ba7dd7afd7",
            "value": " 206/500 [01:55&lt;04:04,  1.20it/s]"
          }
        },
        "f372b67e0935459ba854c308cc81a4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29c75404fa948449a5e797a2acc9eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bedb1dbaedf40a29e9e77452397cb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "034f4c188c504d0d983381273d2073cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7eba784e6143088d258ecd6d4c9f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23994c45fc6a48fc8026c2a8e16bfa4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8127a146e9864f0ebe6080ba7dd7afd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "If you have any problem, e-mail us at ntu-ml-2022spring-ta@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Preliminary work\n",
        "\n",
        "First, we need to install all necessary packages.\n",
        "One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "7a278c37-0a1f-4fda-a543-3662aa515d45",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "!apt update\n",
        "!apt install python-opengl xvfb -y\n",
        "!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d]==0.18.3 in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (4.1.1)\n",
            "Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.7.3)\n",
            "Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "Next, set up virtual display，and import all necessaary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl2nREINDLiw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaEJ8BUCpN9P",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Warning ! Do not revise random seed !!!\n",
        "# Your submission on JudgeBoi will not reproduce your result !!!\n",
        "Make your HW result to be reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV9i8i2YkRbO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "seed = 543 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.set_deterministic(True)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4-xJcbBt09",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "env = gym.make('LunarLander-v2')\n",
        "fix(env, seed) # fix the environment Do not revise this !!!"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkVvTrvWZ5H",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## What Lunar Lander？\n",
        "\n",
        "“LunarLander-v2”is to simulate the situation when the craft lands on the surface of the moon.\n",
        "\n",
        "This task is to enable the craft to land \"safely\" at the pad between the two yellow flags.\n",
        "> Landing pad is always at coordinates (0,0).\n",
        "> Coordinates are the first two numbers in state vector.\n",
        "\n",
        "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
        "\n",
        "\"LunarLander-v2\" actually includes \"Agent\" and \"Environment\". \n",
        "\n",
        "In this homework, we will utilize the function `step()` to control the action of \"Agent\". \n",
        "\n",
        "Then `step()` will return the observation/state and reward given by the \"Environment\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbp82sljvAt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Observation / State\n",
        "\n",
        "First, we can take a look at what an Observation / State looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXZra3N9R5T",
        "outputId": "fbe73506-b188-4d89-f053-8e2e7471dbc8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(-inf, inf, (8,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdfoThbAQ49",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "`Box(8,)`means that observation is an 8-dim vector\n",
        "### Action\n",
        "\n",
        "Actions can be taken by looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1k4dIrBAaKi",
        "outputId": "2b43e278-a937-424e-bf8e-17d2d25ea7f4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dejXT6PHBrPn",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "`Discrete(4)` implies that there are four kinds of actions can be taken by agent.\n",
        "- 0 implies the agent will not take any actions\n",
        "- 2 implies the agent will accelerate downward\n",
        "- 1, 3 implies the agent will accelerate left and right\n",
        "\n",
        "Next, we will try to make the agent interact with the environment. \n",
        "Before taking any actions, we recommend to call `reset()` function to reset the environment. Also, this function will return the initial state of the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4OmrmZgnWA",
        "outputId": "38974194-970f-45ef-ec6f-fd0803ff78da",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "initial_state = env.reset()\n",
        "print(initial_state)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n",
            "  0.          0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx0mEqqgxJ9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Then, we try to get a random action from the agent's action space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkOEXRKgizt",
        "outputId": "24c07a15-2acf-428c-ed3f-f106811de7ba",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "random_action = env.action_space.sample()\n",
        "print(random_action)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mns-bO01g0-J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "More, we can utilize `step()` to make agent act according to the randomly-selected `random_action`.\n",
        "The `step()` function will return four values:\n",
        "- observation / state\n",
        "- reward\n",
        "- done (True/ False)\n",
        "- Other information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_WViSxGgIk9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "observation, reward, done, info = env.step(random_action)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7r126kuCNp",
        "outputId": "316a9b5a-de58-4ced-bdf9-658ef7459713",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(done)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdS8vOihxhc",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Reward\n",
        "\n",
        "\n",
        "> Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQNs77hi0_7",
        "outputId": "26da523e-b66c-45e3-e0db-204f1ff8a081",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(reward)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.8588900517154912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhqp6D-XgHpe",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Random Agent\n",
        "In the end, before we start training, we can see whether a random agent can successfully land the moon or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Y3G0bxoccelv",
        "outputId": "82b3a7af-eb34-42c2-e238-b07ca68f847b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "env.reset()\n",
        "\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Policy Gradient\n",
        "Now, we can build a simple policy network. The network will return one of action in the action space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdmeD-tZew",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class PolicyGradientNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, state):\n",
        "        hid = torch.tanh(self.fc1(state))\n",
        "        hid = torch.tanh(hid)\n",
        "        return F.softmax(self.fc3(hid), dim=-1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n",
        "- `learn()`：update the policy network from log probabilities and rewards.\n",
        "- `sample()`：After receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZo-IxJx286z",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "class PolicyGradientAgent():\n",
        "    \n",
        "    def __init__(self, network):\n",
        "        self.network = network\n",
        "        self.optimizer = optim.SGD(self.network.parameters(), lr=0.001)\n",
        "        \n",
        "    def forward(self, state):\n",
        "        return self.network(state)\n",
        "    def learn(self, log_probs, rewards):\n",
        "        loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def sample(self, state):\n",
        "        action_prob = self.network(torch.FloatTensor(state))\n",
        "        action_dist = Categorical(action_prob)\n",
        "        action = action_dist.sample()\n",
        "        log_prob = action_dist.log_prob(action)\n",
        "        return action.item(), log_prob"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Lastly, build a network and agent to start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIvML-RYjL",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "network = PolicyGradientNetwork()\n",
        "agent = PolicyGradientAgent(network)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training Agent\n",
        "\n",
        "Now let's start to train our agent.\n",
        "Through taking all the interactions between agent and environment as training data, the policy network can learn from all these attempts,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7a680dd0380646beb5d79a2c9c0abd5d",
            "89faed095217421796547389e01e53ac",
            "8b785f3f08ad4781bcb842215fbcdfac",
            "c8c35d7a8e38450ea308c1a11ae81c77",
            "f372b67e0935459ba854c308cc81a4c6",
            "c29c75404fa948449a5e797a2acc9eeb",
            "7bedb1dbaedf40a29e9e77452397cb2b",
            "034f4c188c504d0d983381273d2073cf",
            "5e7eba784e6143088d258ecd6d4c9f2d",
            "23994c45fc6a48fc8026c2a8e16bfa4a",
            "8127a146e9864f0ebe6080ba7dd7afd7"
          ]
        },
        "id": "vg5rxBBaf38_",
        "outputId": "780cf324-2ef6-46d3-b925-86d2be2fce21",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "agent.network.train()  # Switch network into training mode \n",
        "EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
        "NUM_BATCH = 500        # totally update the agent for 400 time\n",
        "rate = 0.99\n",
        "\n",
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "\n",
        "prg_bar = tqdm(range(NUM_BATCH))\n",
        "for batch in prg_bar:\n",
        "\n",
        "    log_probs, rewards = [], []\n",
        "    total_rewards, final_rewards = [], []\n",
        "\n",
        "    # collect trajectory\n",
        "    for episode in range(EPISODE_PER_BATCH):\n",
        "        \n",
        "        state = env.reset()\n",
        "        total_reward, total_step = 0, 0\n",
        "        seq_rewards = []\n",
        "        while True:\n",
        "\n",
        "            action, log_prob = agent.sample(state) # at, log(at|st)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
        "            seq_rewards.append(reward)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            total_step += 1\n",
        "            #rewards.append(reward) # change here\n",
        "            # ! IMPORTANT !\n",
        "            # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n",
        "            #                                                         rewards :     r1, r2 ,r3 ......\n",
        "            # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n",
        "            #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n",
        "            # boss : implement Actor-Critic\n",
        "            if done:\n",
        "                final_rewards.append(reward)\n",
        "                total_rewards.append(total_reward)\n",
        "                # calculate accumulative rewards\n",
        "                for i in range(2, len(seq_rewards)+1):\n",
        "                    seq_rewards[-i] += rate * (seq_rewards[-i+1])\n",
        "                rewards += seq_rewards\n",
        "                \n",
        "                break\n",
        "\n",
        " \n",
        "    print(f\"rewards looks like \", np.shape(rewards))  \n",
        "    print(f\"log_probs looks like \", len(log_probs))     \n",
        "    # record training process\n",
        "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "    avg_total_rewards.append(avg_total_reward)\n",
        "    avg_final_rewards.append(avg_final_reward)\n",
        "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "\n",
        "    # update agent\n",
        "    # rewards = np.concatenate(rewards, axis=0)\n",
        "    rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n",
        "    agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
        "    print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
        "    print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a680dd0380646beb5d79a2c9c0abd5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rewards looks like  (460,)\n",
            "log_probs looks like  460\n",
            "logs prob looks like  torch.Size([460])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([460])\n",
            "rewards looks like  (509,)\n",
            "log_probs looks like  509\n",
            "logs prob looks like  torch.Size([509])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([509])\n",
            "rewards looks like  (416,)\n",
            "log_probs looks like  416\n",
            "logs prob looks like  torch.Size([416])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([416])\n",
            "rewards looks like  (541,)\n",
            "log_probs looks like  541\n",
            "logs prob looks like  torch.Size([541])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([541])\n",
            "rewards looks like  (525,)\n",
            "log_probs looks like  525\n",
            "logs prob looks like  torch.Size([525])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([525])\n",
            "rewards looks like  (489,)\n",
            "log_probs looks like  489\n",
            "logs prob looks like  torch.Size([489])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([489])\n",
            "rewards looks like  (545,)\n",
            "log_probs looks like  545\n",
            "logs prob looks like  torch.Size([545])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([545])\n",
            "rewards looks like  (473,)\n",
            "log_probs looks like  473\n",
            "logs prob looks like  torch.Size([473])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([473])\n",
            "rewards looks like  (467,)\n",
            "log_probs looks like  467\n",
            "logs prob looks like  torch.Size([467])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([467])\n",
            "rewards looks like  (477,)\n",
            "log_probs looks like  477\n",
            "logs prob looks like  torch.Size([477])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([477])\n",
            "rewards looks like  (482,)\n",
            "log_probs looks like  482\n",
            "logs prob looks like  torch.Size([482])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([482])\n",
            "rewards looks like  (606,)\n",
            "log_probs looks like  606\n",
            "logs prob looks like  torch.Size([606])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([606])\n",
            "rewards looks like  (510,)\n",
            "log_probs looks like  510\n",
            "logs prob looks like  torch.Size([510])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([510])\n",
            "rewards looks like  (521,)\n",
            "log_probs looks like  521\n",
            "logs prob looks like  torch.Size([521])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([521])\n",
            "rewards looks like  (483,)\n",
            "log_probs looks like  483\n",
            "logs prob looks like  torch.Size([483])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([483])\n",
            "rewards looks like  (545,)\n",
            "log_probs looks like  545\n",
            "logs prob looks like  torch.Size([545])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([545])\n",
            "rewards looks like  (538,)\n",
            "log_probs looks like  538\n",
            "logs prob looks like  torch.Size([538])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([538])\n",
            "rewards looks like  (497,)\n",
            "log_probs looks like  497\n",
            "logs prob looks like  torch.Size([497])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([497])\n",
            "rewards looks like  (677,)\n",
            "log_probs looks like  677\n",
            "logs prob looks like  torch.Size([677])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([677])\n",
            "rewards looks like  (595,)\n",
            "log_probs looks like  595\n",
            "logs prob looks like  torch.Size([595])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([595])\n",
            "rewards looks like  (1344,)\n",
            "log_probs looks like  1344\n",
            "logs prob looks like  torch.Size([1344])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1344])\n",
            "rewards looks like  (587,)\n",
            "log_probs looks like  587\n",
            "logs prob looks like  torch.Size([587])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([587])\n",
            "rewards looks like  (595,)\n",
            "log_probs looks like  595\n",
            "logs prob looks like  torch.Size([595])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([595])\n",
            "rewards looks like  (542,)\n",
            "log_probs looks like  542\n",
            "logs prob looks like  torch.Size([542])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([542])\n",
            "rewards looks like  (578,)\n",
            "log_probs looks like  578\n",
            "logs prob looks like  torch.Size([578])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([578])\n",
            "rewards looks like  (511,)\n",
            "log_probs looks like  511\n",
            "logs prob looks like  torch.Size([511])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([511])\n",
            "rewards looks like  (503,)\n",
            "log_probs looks like  503\n",
            "logs prob looks like  torch.Size([503])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([503])\n",
            "rewards looks like  (602,)\n",
            "log_probs looks like  602\n",
            "logs prob looks like  torch.Size([602])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([602])\n",
            "rewards looks like  (532,)\n",
            "log_probs looks like  532\n",
            "logs prob looks like  torch.Size([532])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([532])\n",
            "rewards looks like  (499,)\n",
            "log_probs looks like  499\n",
            "logs prob looks like  torch.Size([499])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([499])\n",
            "rewards looks like  (499,)\n",
            "log_probs looks like  499\n",
            "logs prob looks like  torch.Size([499])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([499])\n",
            "rewards looks like  (412,)\n",
            "log_probs looks like  412\n",
            "logs prob looks like  torch.Size([412])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([412])\n",
            "rewards looks like  (514,)\n",
            "log_probs looks like  514\n",
            "logs prob looks like  torch.Size([514])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([514])\n",
            "rewards looks like  (546,)\n",
            "log_probs looks like  546\n",
            "logs prob looks like  torch.Size([546])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([546])\n",
            "rewards looks like  (582,)\n",
            "log_probs looks like  582\n",
            "logs prob looks like  torch.Size([582])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([582])\n",
            "rewards looks like  (520,)\n",
            "log_probs looks like  520\n",
            "logs prob looks like  torch.Size([520])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([520])\n",
            "rewards looks like  (590,)\n",
            "log_probs looks like  590\n",
            "logs prob looks like  torch.Size([590])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([590])\n",
            "rewards looks like  (646,)\n",
            "log_probs looks like  646\n",
            "logs prob looks like  torch.Size([646])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
            "rewards looks like  (510,)\n",
            "log_probs looks like  510\n",
            "logs prob looks like  torch.Size([510])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([510])\n",
            "rewards looks like  (551,)\n",
            "log_probs looks like  551\n",
            "logs prob looks like  torch.Size([551])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([551])\n",
            "rewards looks like  (491,)\n",
            "log_probs looks like  491\n",
            "logs prob looks like  torch.Size([491])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([491])\n",
            "rewards looks like  (612,)\n",
            "log_probs looks like  612\n",
            "logs prob looks like  torch.Size([612])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([612])\n",
            "rewards looks like  (528,)\n",
            "log_probs looks like  528\n",
            "logs prob looks like  torch.Size([528])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([528])\n",
            "rewards looks like  (471,)\n",
            "log_probs looks like  471\n",
            "logs prob looks like  torch.Size([471])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([471])\n",
            "rewards looks like  (554,)\n",
            "log_probs looks like  554\n",
            "logs prob looks like  torch.Size([554])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([554])\n",
            "rewards looks like  (535,)\n",
            "log_probs looks like  535\n",
            "logs prob looks like  torch.Size([535])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([535])\n",
            "rewards looks like  (429,)\n",
            "log_probs looks like  429\n",
            "logs prob looks like  torch.Size([429])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([429])\n",
            "rewards looks like  (518,)\n",
            "log_probs looks like  518\n",
            "logs prob looks like  torch.Size([518])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
            "rewards looks like  (433,)\n",
            "log_probs looks like  433\n",
            "logs prob looks like  torch.Size([433])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([433])\n",
            "rewards looks like  (549,)\n",
            "log_probs looks like  549\n",
            "logs prob looks like  torch.Size([549])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([549])\n",
            "rewards looks like  (464,)\n",
            "log_probs looks like  464\n",
            "logs prob looks like  torch.Size([464])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([464])\n",
            "rewards looks like  (614,)\n",
            "log_probs looks like  614\n",
            "logs prob looks like  torch.Size([614])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([614])\n",
            "rewards looks like  (567,)\n",
            "log_probs looks like  567\n",
            "logs prob looks like  torch.Size([567])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([567])\n",
            "rewards looks like  (530,)\n",
            "log_probs looks like  530\n",
            "logs prob looks like  torch.Size([530])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([530])\n",
            "rewards looks like  (472,)\n",
            "log_probs looks like  472\n",
            "logs prob looks like  torch.Size([472])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([472])\n",
            "rewards looks like  (594,)\n",
            "log_probs looks like  594\n",
            "logs prob looks like  torch.Size([594])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([594])\n",
            "rewards looks like  (481,)\n",
            "log_probs looks like  481\n",
            "logs prob looks like  torch.Size([481])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([481])\n",
            "rewards looks like  (516,)\n",
            "log_probs looks like  516\n",
            "logs prob looks like  torch.Size([516])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([516])\n",
            "rewards looks like  (593,)\n",
            "log_probs looks like  593\n",
            "logs prob looks like  torch.Size([593])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([593])\n",
            "rewards looks like  (404,)\n",
            "log_probs looks like  404\n",
            "logs prob looks like  torch.Size([404])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([404])\n",
            "rewards looks like  (530,)\n",
            "log_probs looks like  530\n",
            "logs prob looks like  torch.Size([530])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([530])\n",
            "rewards looks like  (413,)\n",
            "log_probs looks like  413\n",
            "logs prob looks like  torch.Size([413])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([413])\n",
            "rewards looks like  (691,)\n",
            "log_probs looks like  691\n",
            "logs prob looks like  torch.Size([691])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([691])\n",
            "rewards looks like  (452,)\n",
            "log_probs looks like  452\n",
            "logs prob looks like  torch.Size([452])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([452])\n",
            "rewards looks like  (501,)\n",
            "log_probs looks like  501\n",
            "logs prob looks like  torch.Size([501])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([501])\n",
            "rewards looks like  (519,)\n",
            "log_probs looks like  519\n",
            "logs prob looks like  torch.Size([519])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([519])\n",
            "rewards looks like  (527,)\n",
            "log_probs looks like  527\n",
            "logs prob looks like  torch.Size([527])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([527])\n",
            "rewards looks like  (495,)\n",
            "log_probs looks like  495\n",
            "logs prob looks like  torch.Size([495])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([495])\n",
            "rewards looks like  (514,)\n",
            "log_probs looks like  514\n",
            "logs prob looks like  torch.Size([514])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([514])\n",
            "rewards looks like  (527,)\n",
            "log_probs looks like  527\n",
            "logs prob looks like  torch.Size([527])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([527])\n",
            "rewards looks like  (476,)\n",
            "log_probs looks like  476\n",
            "logs prob looks like  torch.Size([476])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([476])\n",
            "rewards looks like  (543,)\n",
            "log_probs looks like  543\n",
            "logs prob looks like  torch.Size([543])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([543])\n",
            "rewards looks like  (524,)\n",
            "log_probs looks like  524\n",
            "logs prob looks like  torch.Size([524])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([524])\n",
            "rewards looks like  (501,)\n",
            "log_probs looks like  501\n",
            "logs prob looks like  torch.Size([501])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([501])\n",
            "rewards looks like  (500,)\n",
            "log_probs looks like  500\n",
            "logs prob looks like  torch.Size([500])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([500])\n",
            "rewards looks like  (409,)\n",
            "log_probs looks like  409\n",
            "logs prob looks like  torch.Size([409])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([409])\n",
            "rewards looks like  (430,)\n",
            "log_probs looks like  430\n",
            "logs prob looks like  torch.Size([430])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([430])\n",
            "rewards looks like  (517,)\n",
            "log_probs looks like  517\n",
            "logs prob looks like  torch.Size([517])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([517])\n",
            "rewards looks like  (507,)\n",
            "log_probs looks like  507\n",
            "logs prob looks like  torch.Size([507])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([507])\n",
            "rewards looks like  (472,)\n",
            "log_probs looks like  472\n",
            "logs prob looks like  torch.Size([472])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([472])\n",
            "rewards looks like  (475,)\n",
            "log_probs looks like  475\n",
            "logs prob looks like  torch.Size([475])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([475])\n",
            "rewards looks like  (405,)\n",
            "log_probs looks like  405\n",
            "logs prob looks like  torch.Size([405])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([405])\n",
            "rewards looks like  (421,)\n",
            "log_probs looks like  421\n",
            "logs prob looks like  torch.Size([421])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([421])\n",
            "rewards looks like  (523,)\n",
            "log_probs looks like  523\n",
            "logs prob looks like  torch.Size([523])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([523])\n",
            "rewards looks like  (611,)\n",
            "log_probs looks like  611\n",
            "logs prob looks like  torch.Size([611])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([611])\n",
            "rewards looks like  (497,)\n",
            "log_probs looks like  497\n",
            "logs prob looks like  torch.Size([497])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([497])\n",
            "rewards looks like  (549,)\n",
            "log_probs looks like  549\n",
            "logs prob looks like  torch.Size([549])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([549])\n",
            "rewards looks like  (546,)\n",
            "log_probs looks like  546\n",
            "logs prob looks like  torch.Size([546])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([546])\n",
            "rewards looks like  (545,)\n",
            "log_probs looks like  545\n",
            "logs prob looks like  torch.Size([545])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([545])\n",
            "rewards looks like  (469,)\n",
            "log_probs looks like  469\n",
            "logs prob looks like  torch.Size([469])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([469])\n",
            "rewards looks like  (498,)\n",
            "log_probs looks like  498\n",
            "logs prob looks like  torch.Size([498])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([498])\n",
            "rewards looks like  (436,)\n",
            "log_probs looks like  436\n",
            "logs prob looks like  torch.Size([436])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([436])\n",
            "rewards looks like  (1174,)\n",
            "log_probs looks like  1174\n",
            "logs prob looks like  torch.Size([1174])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1174])\n",
            "rewards looks like  (506,)\n",
            "log_probs looks like  506\n",
            "logs prob looks like  torch.Size([506])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([506])\n",
            "rewards looks like  (516,)\n",
            "log_probs looks like  516\n",
            "logs prob looks like  torch.Size([516])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([516])\n",
            "rewards looks like  (545,)\n",
            "log_probs looks like  545\n",
            "logs prob looks like  torch.Size([545])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([545])\n",
            "rewards looks like  (574,)\n",
            "log_probs looks like  574\n",
            "logs prob looks like  torch.Size([574])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([574])\n",
            "rewards looks like  (520,)\n",
            "log_probs looks like  520\n",
            "logs prob looks like  torch.Size([520])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([520])\n",
            "rewards looks like  (561,)\n",
            "log_probs looks like  561\n",
            "logs prob looks like  torch.Size([561])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([561])\n",
            "rewards looks like  (579,)\n",
            "log_probs looks like  579\n",
            "logs prob looks like  torch.Size([579])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([579])\n",
            "rewards looks like  (570,)\n",
            "log_probs looks like  570\n",
            "logs prob looks like  torch.Size([570])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([570])\n",
            "rewards looks like  (510,)\n",
            "log_probs looks like  510\n",
            "logs prob looks like  torch.Size([510])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([510])\n",
            "rewards looks like  (546,)\n",
            "log_probs looks like  546\n",
            "logs prob looks like  torch.Size([546])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([546])\n",
            "rewards looks like  (471,)\n",
            "log_probs looks like  471\n",
            "logs prob looks like  torch.Size([471])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([471])\n",
            "rewards looks like  (479,)\n",
            "log_probs looks like  479\n",
            "logs prob looks like  torch.Size([479])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([479])\n",
            "rewards looks like  (501,)\n",
            "log_probs looks like  501\n",
            "logs prob looks like  torch.Size([501])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([501])\n",
            "rewards looks like  (613,)\n",
            "log_probs looks like  613\n",
            "logs prob looks like  torch.Size([613])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([613])\n",
            "rewards looks like  (428,)\n",
            "log_probs looks like  428\n",
            "logs prob looks like  torch.Size([428])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([428])\n",
            "rewards looks like  (562,)\n",
            "log_probs looks like  562\n",
            "logs prob looks like  torch.Size([562])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([562])\n",
            "rewards looks like  (528,)\n",
            "log_probs looks like  528\n",
            "logs prob looks like  torch.Size([528])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([528])\n",
            "rewards looks like  (464,)\n",
            "log_probs looks like  464\n",
            "logs prob looks like  torch.Size([464])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([464])\n",
            "rewards looks like  (637,)\n",
            "log_probs looks like  637\n",
            "logs prob looks like  torch.Size([637])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([637])\n",
            "rewards looks like  (547,)\n",
            "log_probs looks like  547\n",
            "logs prob looks like  torch.Size([547])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([547])\n",
            "rewards looks like  (539,)\n",
            "log_probs looks like  539\n",
            "logs prob looks like  torch.Size([539])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([539])\n",
            "rewards looks like  (550,)\n",
            "log_probs looks like  550\n",
            "logs prob looks like  torch.Size([550])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([550])\n",
            "rewards looks like  (483,)\n",
            "log_probs looks like  483\n",
            "logs prob looks like  torch.Size([483])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([483])\n",
            "rewards looks like  (577,)\n",
            "log_probs looks like  577\n",
            "logs prob looks like  torch.Size([577])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([577])\n",
            "rewards looks like  (528,)\n",
            "log_probs looks like  528\n",
            "logs prob looks like  torch.Size([528])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([528])\n",
            "rewards looks like  (527,)\n",
            "log_probs looks like  527\n",
            "logs prob looks like  torch.Size([527])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([527])\n",
            "rewards looks like  (421,)\n",
            "log_probs looks like  421\n",
            "logs prob looks like  torch.Size([421])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([421])\n",
            "rewards looks like  (591,)\n",
            "log_probs looks like  591\n",
            "logs prob looks like  torch.Size([591])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([591])\n",
            "rewards looks like  (546,)\n",
            "log_probs looks like  546\n",
            "logs prob looks like  torch.Size([546])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([546])\n",
            "rewards looks like  (597,)\n",
            "log_probs looks like  597\n",
            "logs prob looks like  torch.Size([597])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([597])\n",
            "rewards looks like  (630,)\n",
            "log_probs looks like  630\n",
            "logs prob looks like  torch.Size([630])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([630])\n",
            "rewards looks like  (563,)\n",
            "log_probs looks like  563\n",
            "logs prob looks like  torch.Size([563])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([563])\n",
            "rewards looks like  (632,)\n",
            "log_probs looks like  632\n",
            "logs prob looks like  torch.Size([632])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([632])\n",
            "rewards looks like  (1449,)\n",
            "log_probs looks like  1449\n",
            "logs prob looks like  torch.Size([1449])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1449])\n",
            "rewards looks like  (559,)\n",
            "log_probs looks like  559\n",
            "logs prob looks like  torch.Size([559])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([559])\n",
            "rewards looks like  (564,)\n",
            "log_probs looks like  564\n",
            "logs prob looks like  torch.Size([564])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([564])\n",
            "rewards looks like  (525,)\n",
            "log_probs looks like  525\n",
            "logs prob looks like  torch.Size([525])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([525])\n",
            "rewards looks like  (648,)\n",
            "log_probs looks like  648\n",
            "logs prob looks like  torch.Size([648])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([648])\n",
            "rewards looks like  (501,)\n",
            "log_probs looks like  501\n",
            "logs prob looks like  torch.Size([501])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([501])\n",
            "rewards looks like  (573,)\n",
            "log_probs looks like  573\n",
            "logs prob looks like  torch.Size([573])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([573])\n",
            "rewards looks like  (674,)\n",
            "log_probs looks like  674\n",
            "logs prob looks like  torch.Size([674])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([674])\n",
            "rewards looks like  (582,)\n",
            "log_probs looks like  582\n",
            "logs prob looks like  torch.Size([582])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([582])\n",
            "rewards looks like  (649,)\n",
            "log_probs looks like  649\n",
            "logs prob looks like  torch.Size([649])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([649])\n",
            "rewards looks like  (577,)\n",
            "log_probs looks like  577\n",
            "logs prob looks like  torch.Size([577])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([577])\n",
            "rewards looks like  (646,)\n",
            "log_probs looks like  646\n",
            "logs prob looks like  torch.Size([646])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
            "rewards looks like  (673,)\n",
            "log_probs looks like  673\n",
            "logs prob looks like  torch.Size([673])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([673])\n",
            "rewards looks like  (708,)\n",
            "log_probs looks like  708\n",
            "logs prob looks like  torch.Size([708])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([708])\n",
            "rewards looks like  (706,)\n",
            "log_probs looks like  706\n",
            "logs prob looks like  torch.Size([706])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([706])\n",
            "rewards looks like  (571,)\n",
            "log_probs looks like  571\n",
            "logs prob looks like  torch.Size([571])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([571])\n",
            "rewards looks like  (591,)\n",
            "log_probs looks like  591\n",
            "logs prob looks like  torch.Size([591])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([591])\n",
            "rewards looks like  (1588,)\n",
            "log_probs looks like  1588\n",
            "logs prob looks like  torch.Size([1588])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1588])\n",
            "rewards looks like  (566,)\n",
            "log_probs looks like  566\n",
            "logs prob looks like  torch.Size([566])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([566])\n",
            "rewards looks like  (713,)\n",
            "log_probs looks like  713\n",
            "logs prob looks like  torch.Size([713])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([713])\n",
            "rewards looks like  (596,)\n",
            "log_probs looks like  596\n",
            "logs prob looks like  torch.Size([596])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([596])\n",
            "rewards looks like  (611,)\n",
            "log_probs looks like  611\n",
            "logs prob looks like  torch.Size([611])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([611])\n",
            "rewards looks like  (633,)\n",
            "log_probs looks like  633\n",
            "logs prob looks like  torch.Size([633])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([633])\n",
            "rewards looks like  (731,)\n",
            "log_probs looks like  731\n",
            "logs prob looks like  torch.Size([731])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([731])\n",
            "rewards looks like  (669,)\n",
            "log_probs looks like  669\n",
            "logs prob looks like  torch.Size([669])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([669])\n",
            "rewards looks like  (566,)\n",
            "log_probs looks like  566\n",
            "logs prob looks like  torch.Size([566])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([566])\n",
            "rewards looks like  (636,)\n",
            "log_probs looks like  636\n",
            "logs prob looks like  torch.Size([636])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([636])\n",
            "rewards looks like  (507,)\n",
            "log_probs looks like  507\n",
            "logs prob looks like  torch.Size([507])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([507])\n",
            "rewards looks like  (716,)\n",
            "log_probs looks like  716\n",
            "logs prob looks like  torch.Size([716])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([716])\n",
            "rewards looks like  (765,)\n",
            "log_probs looks like  765\n",
            "logs prob looks like  torch.Size([765])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([765])\n",
            "rewards looks like  (554,)\n",
            "log_probs looks like  554\n",
            "logs prob looks like  torch.Size([554])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([554])\n",
            "rewards looks like  (920,)\n",
            "log_probs looks like  920\n",
            "logs prob looks like  torch.Size([920])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([920])\n",
            "rewards looks like  (701,)\n",
            "log_probs looks like  701\n",
            "logs prob looks like  torch.Size([701])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([701])\n",
            "rewards looks like  (572,)\n",
            "log_probs looks like  572\n",
            "logs prob looks like  torch.Size([572])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([572])\n",
            "rewards looks like  (610,)\n",
            "log_probs looks like  610\n",
            "logs prob looks like  torch.Size([610])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([610])\n",
            "rewards looks like  (755,)\n",
            "log_probs looks like  755\n",
            "logs prob looks like  torch.Size([755])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([755])\n",
            "rewards looks like  (804,)\n",
            "log_probs looks like  804\n",
            "logs prob looks like  torch.Size([804])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([804])\n",
            "rewards looks like  (802,)\n",
            "log_probs looks like  802\n",
            "logs prob looks like  torch.Size([802])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([802])\n",
            "rewards looks like  (788,)\n",
            "log_probs looks like  788\n",
            "logs prob looks like  torch.Size([788])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([788])\n",
            "rewards looks like  (697,)\n",
            "log_probs looks like  697\n",
            "logs prob looks like  torch.Size([697])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([697])\n",
            "rewards looks like  (646,)\n",
            "log_probs looks like  646\n",
            "logs prob looks like  torch.Size([646])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
            "rewards looks like  (1286,)\n",
            "log_probs looks like  1286\n",
            "logs prob looks like  torch.Size([1286])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1286])\n",
            "rewards looks like  (937,)\n",
            "log_probs looks like  937\n",
            "logs prob looks like  torch.Size([937])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([937])\n",
            "rewards looks like  (773,)\n",
            "log_probs looks like  773\n",
            "logs prob looks like  torch.Size([773])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([773])\n",
            "rewards looks like  (844,)\n",
            "log_probs looks like  844\n",
            "logs prob looks like  torch.Size([844])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([844])\n",
            "rewards looks like  (782,)\n",
            "log_probs looks like  782\n",
            "logs prob looks like  torch.Size([782])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([782])\n",
            "rewards looks like  (729,)\n",
            "log_probs looks like  729\n",
            "logs prob looks like  torch.Size([729])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([729])\n",
            "rewards looks like  (1649,)\n",
            "log_probs looks like  1649\n",
            "logs prob looks like  torch.Size([1649])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1649])\n",
            "rewards looks like  (851,)\n",
            "log_probs looks like  851\n",
            "logs prob looks like  torch.Size([851])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([851])\n",
            "rewards looks like  (763,)\n",
            "log_probs looks like  763\n",
            "logs prob looks like  torch.Size([763])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([763])\n",
            "rewards looks like  (1585,)\n",
            "log_probs looks like  1585\n",
            "logs prob looks like  torch.Size([1585])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1585])\n",
            "rewards looks like  (962,)\n",
            "log_probs looks like  962\n",
            "logs prob looks like  torch.Size([962])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([962])\n",
            "rewards looks like  (657,)\n",
            "log_probs looks like  657\n",
            "logs prob looks like  torch.Size([657])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([657])\n",
            "rewards looks like  (605,)\n",
            "log_probs looks like  605\n",
            "logs prob looks like  torch.Size([605])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([605])\n",
            "rewards looks like  (677,)\n",
            "log_probs looks like  677\n",
            "logs prob looks like  torch.Size([677])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([677])\n",
            "rewards looks like  (838,)\n",
            "log_probs looks like  838\n",
            "logs prob looks like  torch.Size([838])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([838])\n",
            "rewards looks like  (536,)\n",
            "log_probs looks like  536\n",
            "logs prob looks like  torch.Size([536])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([536])\n",
            "rewards looks like  (711,)\n",
            "log_probs looks like  711\n",
            "logs prob looks like  torch.Size([711])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([711])\n",
            "rewards looks like  (888,)\n",
            "log_probs looks like  888\n",
            "logs prob looks like  torch.Size([888])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([888])\n",
            "rewards looks like  (699,)\n",
            "log_probs looks like  699\n",
            "logs prob looks like  torch.Size([699])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([699])\n",
            "rewards looks like  (646,)\n",
            "log_probs looks like  646\n",
            "logs prob looks like  torch.Size([646])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
            "rewards looks like  (716,)\n",
            "log_probs looks like  716\n",
            "logs prob looks like  torch.Size([716])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([716])\n",
            "rewards looks like  (629,)\n",
            "log_probs looks like  629\n",
            "logs prob looks like  torch.Size([629])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([629])\n",
            "rewards looks like  (912,)\n",
            "log_probs looks like  912\n",
            "logs prob looks like  torch.Size([912])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([912])\n",
            "rewards looks like  (739,)\n",
            "log_probs looks like  739\n",
            "logs prob looks like  torch.Size([739])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([739])\n",
            "rewards looks like  (931,)\n",
            "log_probs looks like  931\n",
            "logs prob looks like  torch.Size([931])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([931])\n",
            "rewards looks like  (1774,)\n",
            "log_probs looks like  1774\n",
            "logs prob looks like  torch.Size([1774])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1774])\n",
            "rewards looks like  (661,)\n",
            "log_probs looks like  661\n",
            "logs prob looks like  torch.Size([661])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([661])\n",
            "rewards looks like  (780,)\n",
            "log_probs looks like  780\n",
            "logs prob looks like  torch.Size([780])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([780])\n",
            "rewards looks like  (861,)\n",
            "log_probs looks like  861\n",
            "logs prob looks like  torch.Size([861])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([861])\n",
            "rewards looks like  (784,)\n",
            "log_probs looks like  784\n",
            "logs prob looks like  torch.Size([784])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([784])\n",
            "rewards looks like  (752,)\n",
            "log_probs looks like  752\n",
            "logs prob looks like  torch.Size([752])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([752])\n",
            "rewards looks like  (1928,)\n",
            "log_probs looks like  1928\n",
            "logs prob looks like  torch.Size([1928])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1928])\n",
            "rewards looks like  (702,)\n",
            "log_probs looks like  702\n",
            "logs prob looks like  torch.Size([702])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([702])\n",
            "rewards looks like  (687,)\n",
            "log_probs looks like  687\n",
            "logs prob looks like  torch.Size([687])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([687])\n",
            "rewards looks like  (669,)\n",
            "log_probs looks like  669\n",
            "logs prob looks like  torch.Size([669])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([669])\n",
            "rewards looks like  (1635,)\n",
            "log_probs looks like  1635\n",
            "logs prob looks like  torch.Size([1635])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1635])\n",
            "rewards looks like  (679,)\n",
            "log_probs looks like  679\n",
            "logs prob looks like  torch.Size([679])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([679])\n",
            "rewards looks like  (712,)\n",
            "log_probs looks like  712\n",
            "logs prob looks like  torch.Size([712])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([712])\n",
            "rewards looks like  (770,)\n",
            "log_probs looks like  770\n",
            "logs prob looks like  torch.Size([770])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([770])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Training Result\n",
        "During the training process, we recorded `avg_total_reward`, which represents the average total reward of episodes before updating the policy network.\n",
        "\n",
        "Theoretically, if the agent becomes better, the `avg_total_reward` will increase.\n",
        "The visualization of the training process is shown below:  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZYOI8H10SHN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "plt.plot(avg_total_rewards)\n",
        "plt.title(\"Total Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In addition, `avg_final_reward` represents average final rewards of episodes. To be specific, final rewards is the last reward received in one episode, indicating whether the craft lands successfully or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txDZ5vlGWz5w",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "plt.plot(avg_final_rewards)\n",
        "plt.title(\"Final Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Testing\n",
        "The testing result will be the average reward of 5 testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFuUKKRYH73",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "fix(env, seed)\n",
        "agent.network.eval()  # set the network into evaluation mode\n",
        "NUM_OF_TEST = 5 # Do not revise this !!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "      action, _ = agent.sample(state)\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      img.set_data(env.render(mode='rgb_array'))\n",
        "      display.display(plt.gcf())\n",
        "      display.clear_output(wait=True)\n",
        "      \n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "\n",
        "  action_list.append(actions) # save the result of testing \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aex7mcKr0J01",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(test_total_reward)\n",
        "print(np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Action list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGAH4YWDpp4u",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkmwucrHMen",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Analysis of actions taken by agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdAItjj1nxw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Saving the result of Model Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsMkGmIY42b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "PATH = \"Action_List.npy\" # Can be modified into the name or path you want\n",
        "np.save(PATH ,np.array(action_list)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asK7WfbkaLjt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### This is the file you need to submit !!!\n",
        "Download the testing result to your device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-CqyhHzaWAL",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seT4NUmWmAZ1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Server \n",
        "The code below simulate the environment on the judge server. Can be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U69c-YTxaw6b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "action_list = np.load(PATH,allow_pickle=True) # The action list you upload\n",
        "seed = 543 # Do not revise this\n",
        "fix(env, seed)\n",
        "\n",
        "agent.network.eval()  # set network to evaluation mode\n",
        "\n",
        "test_total_reward = []\n",
        "if len(action_list) != 5:\n",
        "  print(\"Wrong format of file !!!\")\n",
        "  exit(0)\n",
        "for actions in action_list:\n",
        "  state = env.reset()\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "\n",
        "  for action in actions:\n",
        "  \n",
        "      state, reward, done, _ = env.step(action)\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjFBWwQP1hVe",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Your score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpJpZz3Wbm0X",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Reference\n",
        "\n",
        "Below are some useful tips for you to get high score.\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    }
  ]
}