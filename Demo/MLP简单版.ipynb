{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data and test_data shape (47439, 41) (31626, 40)\n",
      "Type                 174\n",
      "Heating              2660\n",
      "Cooling              911\n",
      "Parking              9913\n",
      "Bedrooms             278\n",
      "Region               1259\n",
      "Elementary School    3568\n",
      "Middle School        809\n",
      "High School          922\n",
      "Flooring             1740\n",
      "Heating features     1763\n",
      "Cooling features     596\n",
      "Appliances included  11290\n",
      "Laundry features     3031\n",
      "Parking features     9695\n",
      "before one hot code (79065, 19)\n",
      "after one hot code (79065, 470)\n",
      "train feature shape: torch.Size([47439, 470])\n",
      "test feature shape: torch.Size([31626, 470])\n",
      "train label shape: torch.Size([47439, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:2bzkrupl) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f175b2bf48e347d0b295a9c2d5813652"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">eager-feather-3</strong>: <a href=\"https://wandb.ai/moye12325/kaggle_predict/runs/2bzkrupl\" target=\"_blank\">https://wandb.ai/moye12325/kaggle_predict/runs/2bzkrupl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20220612_034842-2bzkrupl\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:2bzkrupl). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.18"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Projects\\DeepLearning\\Demo\\wandb\\run-20220612_151303-3kuhtncz</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/moye12325/kaggle_predict/runs/3kuhtncz\" target=\"_blank\">laced-microwave-17</a></strong> to <a href=\"https://wandb.ai/moye12325/kaggle_predict\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network: MLP(\n",
      "  (layer1): Linear(in_features=470, out_features=256, bias=True)\n",
      "  (layer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51/2000 [00:40<25:21,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 50 rmse loss value is: 0.3635750412940979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/2000 [01:20<26:12,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 100 rmse loss value is: 0.23198802769184113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 151/2000 [02:02<24:51,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 150 rmse loss value is: 0.23053652048110962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/2000 [02:42<24:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 200 rmse loss value is: 0.2288118153810501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 251/2000 [03:22<23:37,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 250 rmse loss value is: 0.2326572984457016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 301/2000 [04:02<22:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 300 rmse loss value is: 0.23784029483795166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 351/2000 [04:41<21:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 350 rmse loss value is: 0.2391752302646637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 401/2000 [05:20<20:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 400 rmse loss value is: 0.24509213864803314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 451/2000 [05:59<19:50,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 450 rmse loss value is: 0.24015581607818604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 501/2000 [06:38<20:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 500 rmse loss value is: 0.2559889256954193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 551/2000 [07:17<19:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 550 rmse loss value is: 0.2999950051307678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 601/2000 [07:56<18:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 600 rmse loss value is: 0.3024503290653229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 651/2000 [08:35<17:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 650 rmse loss value is: 0.3513205051422119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 701/2000 [09:14<16:38,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 700 rmse loss value is: 0.36101698875427246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 751/2000 [09:53<16:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 750 rmse loss value is: 0.3727125823497772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 801/2000 [10:32<15:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 800 rmse loss value is: 0.42057356238365173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 851/2000 [11:14<16:52,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 850 rmse loss value is: 0.39280402660369873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 901/2000 [11:56<16:06,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 900 rmse loss value is: 0.4425584077835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 951/2000 [12:38<14:58,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 950 rmse loss value is: 0.4918777644634247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1001/2000 [13:21<14:34,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1000 rmse loss value is: 0.4947948753833771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1051/2000 [14:03<13:22,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1050 rmse loss value is: 0.5482037663459778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1101/2000 [14:46<13:32,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1100 rmse loss value is: 0.5456303358078003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1151/2000 [15:28<11:43,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1150 rmse loss value is: 0.5294300317764282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1201/2000 [16:10<11:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1200 rmse loss value is: 0.5961485505104065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1251/2000 [16:52<10:45,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1250 rmse loss value is: 0.576357364654541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1301/2000 [17:32<08:55,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1300 rmse loss value is: 0.5946934223175049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1351/2000 [18:14<09:07,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1350 rmse loss value is: 0.5888828635215759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1401/2000 [18:55<08:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1400 rmse loss value is: 0.5864478349685669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1451/2000 [19:36<07:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1450 rmse loss value is: 0.615331768989563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1501/2000 [20:17<06:44,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1500 rmse loss value is: 0.5999572277069092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1551/2000 [20:58<06:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1550 rmse loss value is: 0.6292240023612976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1601/2000 [21:39<05:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1600 rmse loss value is: 0.6633264422416687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1651/2000 [22:19<04:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1650 rmse loss value is: 0.6990796327590942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1701/2000 [23:00<04:08,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1700 rmse loss value is: 0.6621972322463989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1751/2000 [23:41<03:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1750 rmse loss value is: 0.7108193635940552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1801/2000 [24:21<02:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1800 rmse loss value is: 0.695854663848877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1851/2000 [25:02<02:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1850 rmse loss value is: 0.7372110486030579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1901/2000 [25:43<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1900 rmse loss value is: 0.709581732749939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1951/2000 [26:23<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1950 rmse loss value is: 0.6904146671295166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [27:03<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 1999 rmse loss value is: 0.7546101808547974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b22f5625d8b4d1eaec88885adc118a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▅▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▅▅▄▆▅▆▅▆▆▅▅▆▆▅▇▇▇█▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1999</td></tr><tr><td>loss</td><td>0.75461</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">laced-microwave-17</strong>: <a href=\"https://wandb.ai/moye12325/kaggle_predict/runs/3kuhtncz\" target=\"_blank\">https://wandb.ai/moye12325/kaggle_predict/runs/3kuhtncz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20220612_151303-3kuhtncz\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.18"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Projects\\DeepLearning\\Demo\\wandb\\run-20220612_154023-2wlpq9du</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/moye12325/kaggle_predict/runs/2wlpq9du\" target=\"_blank\">dauntless-yogurt-18</a></strong> to <a href=\"https://wandb.ai/moye12325/kaggle_predict\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint_19676'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 155>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    147\u001B[0m k, num_epochs, lr, weight_decay, batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m0.0005\u001B[39m, \u001B[38;5;241m0.08\u001B[39m, \u001B[38;5;241m256\u001B[39m\n\u001B[0;32m    148\u001B[0m wandb\u001B[38;5;241m.\u001B[39minit(project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkaggle_predict\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    149\u001B[0m            config\u001B[38;5;241m=\u001B[39m{ \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: lr,\n\u001B[0;32m    150\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m: weight_decay,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    153\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetwork\u001B[39m\u001B[38;5;124m\"\u001B[39m: net_list}\n\u001B[0;32m    154\u001B[0m           )\n\u001B[1;32m--> 155\u001B[0m net\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcheckpoint_19676\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetwork:\u001B[39m\u001B[38;5;124m\"\u001B[39m,net)\n\u001B[0;32m    157\u001B[0m net\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py:699\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    697\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 699\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    701\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m    702\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m    704\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py:231\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 231\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py:212\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 212\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'checkpoint_19676'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import wandb\n",
    "\n",
    "NUM_SAVE = 50\n",
    "net_list = \"in->256->64\"\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,256)\n",
    "        self.layer2 = nn.Linear(256,64)\n",
    "        self.out = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.layer1(X))\n",
    "        X = F.relu(self.layer2(X))\n",
    "        return self.out(X)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(\"train_data and test_data shape\",train_data.shape,test_data.shape)\n",
    "\n",
    "# 去掉冗余数据\n",
    "redundant_cols = ['Address', 'Summary', 'City', 'State']\n",
    "for c in redundant_cols:\n",
    "    del test_data[c], train_data[c]\n",
    "\n",
    "# 数据预处理\n",
    "large_vel_cols = ['Lot', 'Total interior livable area', 'Tax assessed value', 'Annual tax amount', 'Listed Price', 'Last Sold Price']\n",
    "for c in large_vel_cols:\n",
    "    train_data[c] = np.log(train_data[c]+1)\n",
    "    if c!='Sold Price':\n",
    "        test_data[c] = np.log(test_data[c]+1)\n",
    "\n",
    "# 把train和test去除id后放一起，train也要去掉label\n",
    "all_features = pd.concat((train_data.iloc[:,2:],test_data.iloc[:,1:]))\n",
    "\n",
    "# 时间数据赋日期格式\n",
    "all_features['Listed On'] = pd.to_datetime(all_features['Listed On'], format=\"%Y-%m-%d\")\n",
    "all_features['Last Sold On'] = pd.to_datetime(all_features['Last Sold On'], format=\"%Y-%m-%d\")\n",
    "\n",
    "for in_object in all_features.dtypes[all_features.dtypes=='object'].index:\n",
    "    print(in_object.ljust(20),len(all_features[in_object].unique()))\n",
    "\n",
    "# 查询数字列 ->缺失数据赋0 -> 归一化\n",
    "numeric_features = all_features.dtypes[all_features.dtypes == 'float64'].index\n",
    "all_features = all_features.fillna(method='bfill', axis=0).fillna(0)\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "features = list(numeric_features)\n",
    "features.extend(['Type','Bedrooms'])   # 加上类别数相对较少的Type, ,'Cooling features'\n",
    "all_features = all_features[features]\n",
    "\n",
    "print('before one hot code',all_features.shape)\n",
    "all_features = pd.get_dummies(all_features,dummy_na=True)\n",
    "all_features.shape\n",
    "print('after one hot code',all_features.shape)\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)\n",
    "print('train feature shape:', train_features.shape)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float)\n",
    "print('test feature shape:', test_features.shape)\n",
    "train_labels = torch.tensor(train_data['Sold Price'].values.reshape(-1, 1), dtype=torch.float)\n",
    "print('train label shape:', train_labels.shape)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "net = MLP(in_features).to(device)\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "    rmse = torch.sqrt(criterion(torch.log(clipped_preds),\n",
    "                           torch.log(labels)))\n",
    "    return rmse.item()\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    wandb.watch(net)\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        record_loss = log_rmse(net.to('cpu'), train_features, train_labels)\n",
    "        wandb.log({'loss': record_loss,'epoch': epoch})\n",
    "        train_ls.append(record_loss)\n",
    "        if (epoch%NUM_SAVE==0 and epoch!=0) or (epoch==num_epochs-1):\n",
    "            torch.save(net.state_dict(),'checkpoint_'+str(epoch))\n",
    "            print('save checkpoints on:', epoch, 'rmse loss value is:', record_loss)\n",
    "        del X, y\n",
    "        net.to(device)\n",
    "    wandb.finish()\n",
    "    return train_ls, test_ls\n",
    "\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 2000, 0.005, 0.05, 256\n",
    "wandb.init(project=\"kaggle_predict\",\n",
    "           config={ \"learning_rate\": lr,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"total_run\": num_epochs,\n",
    "                    \"network\": net_list}\n",
    "          )\n",
    "print(\"network:\",net)\n",
    "\n",
    "train_ls, valid_ls = train(net, train_features,train_labels,None,None, num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "# 使用现有训练好的net\n",
    "net.to('cpu')\n",
    "# 将网络应用于测试集。\n",
    "preds = net(test_features).detach().numpy()\n",
    "\n",
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "net.to('cpu')\n",
    "preds = net(test_features).detach().numpy()\n",
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 读取已有 继续进行训练\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 500, 0.0005, 0.08, 256\n",
    "wandb.init(project=\"kaggle_predict\",\n",
    "           config={ \"learning_rate\": lr,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"total_run\": num_epochs,\n",
    "                    \"network\": net_list}\n",
    "          )\n",
    "net.load_state_dict(torch.load('checkpoint_19676'))\n",
    "print(\"network:\",net)\n",
    "net.to(device)\n",
    "train_ls, valid_ls = train(net, train_features,train_labels,None,None, num_epochs, lr, weight_decay, batch_size)\n",
    "net.to('cpu')\n",
    "preds = net(test_features).detach().numpy()\n",
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 读取网络参数应用于测试集\n",
    "net = []\n",
    "net = MLP(test_features.shape[1])\n",
    "net.load_state_dict(torch.load('checkpoint_250'))\n",
    "net.to('cpu')\n",
    "preds = net(test_features).detach().numpy()\n",
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(len(all_features['Type'].unique()))\n",
    "print(len(all_features['Heating'].unique()))\n",
    "print(len(all_features['Cooling'].unique()))\n",
    "print(len(all_features['Parking'].unique()))\n",
    "print(len(all_features['Bedrooms'].unique()))\n",
    "print(len(all_features['Region'].unique()))\n",
    "print(len(all_features['Elementary School'].unique()))\n",
    "print(len(all_features['Middle School'].unique()))\n",
    "print(len(all_features['High School'].unique()))\n",
    "print(len(all_features['Flooring'].unique()))\n",
    "print(len(all_features['Heating features'].unique()))\n",
    "print(len(all_features['Cooling features'].unique()))\n",
    "print(len(all_features['Appliances included'].unique()))\n",
    "print(len(all_features['Laundry features'].unique()))\n",
    "print(len(all_features['Parking features'].unique()))\n",
    "print(len(all_features['City'].unique()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}